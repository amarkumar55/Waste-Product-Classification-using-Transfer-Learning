{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74a5c68",
   "metadata": {},
   "source": [
    "### Waste Product Classification Using Transfer Learning (VGG16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218d9d5",
   "metadata": {},
   "source": [
    "This project builds an image classification system using transfer learning with\n",
    "the VGG16 architecture to classify waste materials into Organic (O) and\n",
    "Recyclable (R) categories. The model is trained in two stages: feature extraction\n",
    "and fine-tuning. Performance is evaluated using accuracy and classification\n",
    "reports, and predictions are visualized to interpret model behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f61885",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18709e27",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e6990",
   "metadata": {},
   "source": [
    "### Download dataset and extract file from data source url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14464f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_URL = \"DATA_SOURCE_URL\"\n",
    "\n",
    "ZIP_NAME = \"dataset.zip\"\n",
    "\n",
    "with requests.get(DATASET_URL, stream=True) as response:\n",
    "    response.raise_for_status()\n",
    "    with open(ZIP_NAME, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "def extract_zip(zip_name):\n",
    "    with zipfile.ZipFile(zip_name, \"r\") as zip_ref:\n",
    "        members = zip_ref.infolist()\n",
    "        with tqdm(total=len(members), unit=\"file\") as pbar:\n",
    "            for member in members:\n",
    "                zip_ref.extract(member)\n",
    "                pbar.update(1)\n",
    "\n",
    "extract_zip(ZIP_NAME)\n",
    "os.remove(ZIP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8ab64",
   "metadata": {},
   "source": [
    "### Configuration for dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f5feb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_ROWS, IMG_COLS = 150, 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "\n",
    "TRAIN_DIR = \"dataset/train\"\n",
    "TEST_DIR = \"dataset/test\"\n",
    "\n",
    "CLASS_NAMES = [\"O\", \"R\"]  # O = Organic, R = Recyclable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4b767",
   "metadata": {},
   "source": [
    "### Data Generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f22e04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d41f1e",
   "metadata": {},
   "source": [
    "### Feature Extraction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a56b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_ROWS, IMG_COLS, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    return 1e-5 * np.exp(-0.1 * epoch)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"vgg16_feature_extraction.keras\", save_best_only=True),\n",
    "    LearningRateScheduler(exp_decay)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c53204",
   "metadata": {},
   "source": [
    "### Train Feature Extraction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fd75e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history_extract = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ccef61",
   "metadata": {},
   "source": [
    "### Final-tuning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10fe51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if layer.name in [\"block5_conv1\", \"block5_conv2\", \"block5_conv3\"]:\n",
    "        layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"vgg16_fine_tuned.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea214a",
   "metadata": {},
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee5e49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_extract = tf.keras.models.load_model(\"vgg16_feature_extraction.keras\")\n",
    "model_finetune = tf.keras.models.load_model(\"vgg16_fine_tuned.keras\")\n",
    "\n",
    "test_imgs, test_labels = [], []\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    files = glob.glob(f\"{TEST_DIR}/{class_name}/*\")[:50]\n",
    "    for f in files:\n",
    "        img = tf.keras.preprocessing.image.load_img(f, target_size=(IMG_ROWS, IMG_COLS))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        test_imgs.append(img)\n",
    "        test_labels.append(class_name)\n",
    "\n",
    "test_imgs = np.array(test_imgs) / 255.0\n",
    "\n",
    "num2class = lambda x: [\"O\" if i[0] < 0.5 else \"R\" for i in x]\n",
    "\n",
    "pred_extract = num2class(model_extract.predict(test_imgs))\n",
    "pred_finetune = num2class(model_finetune.predict(test_imgs))\n",
    "\n",
    "print(\"Feature Extraction Model\")\n",
    "print(metrics.classification_report(test_labels, pred_extract))\n",
    "\n",
    "print(\"Fine-Tuned Model\")\n",
    "print(metrics.classification_report(test_labels, pred_finetune))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
